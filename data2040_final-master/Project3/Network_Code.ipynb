{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#credit to pascal voc 2008 data set\n",
    "\n",
    "@misc{pascal-voc-2008,\n",
    "\tauthor = \"Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.\",\n",
    "\ttitle = \"The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2008 {(VOC2008)} {R}esults\",\n",
    "\thowpublished = \"http://www.pascal-network.org/challenges/VOC/voc2008/workshop/index.html\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import os, shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the data from the folders created to hold the original images and their corresponding image with a watermark. Standardize and reshape the images to fit into the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5096 images belonging to 1 classes.\n",
      "Found 5096 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "raw_dir = '/gpfs_home/guest321/FinalProj/FinalProjectFinal/RAWS/'\n",
    "wat_dir = '/gpfs_home/guest321/FinalProj/FinalProjectFinal/WATS/'\n",
    "\n",
    "raw_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "raw_generator = raw_datagen.flow_from_directory(\n",
    "        raw_dir,  # this is the target directory\n",
    "        target_size=(250, 250),\n",
    "        batch_size=5096, shuffle = 0,\n",
    "        class_mode=\"categorical\")\n",
    "\n",
    "wat_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "wat_generator = wat_datagen.flow_from_directory(\n",
    "        wat_dir,  # this is the target directory\n",
    "        target_size=(250, 250),\n",
    "        batch_size=5096, shuffle = 0,\n",
    "        class_mode=\"categorical\")\n",
    "\n",
    "x_raw,y = raw_generator.next()\n",
    "x_wat,y = wat_generator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_raw = x_raw[0:4500]\n",
    "x_train_wat = x_wat[0:4500]\n",
    "\n",
    "x_val_raw = x_raw[4500:4900]\n",
    "x_val_wat = x_wat[4500:4900]\n",
    "\n",
    "x_train = np.vstack((x_train_raw, x_train_wat))\n",
    "x_val = np.vstack((x_val_raw, x_val_wat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.repeat([0.], 4500)\n",
    "y_train = np.append(y_train, np.repeat([1.], 4500))\n",
    "\n",
    "y_val = np.repeat([0.], 400)\n",
    "y_val = np.append(y_val, np.repeat([1.], 400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the response variables for each data set: images with a watermark have a response of 1, while images without a watermark have a response of 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 800 samples\n",
      "Epoch 1/30\n",
      "9000/9000 [==============================] - 26s 3ms/sample - loss: 0.7138 - acc: 0.5132 - val_loss: 0.6797 - val_acc: 0.5550\n",
      "Epoch 2/30\n",
      "9000/9000 [==============================] - 19s 2ms/sample - loss: 0.6238 - acc: 0.6436 - val_loss: 0.4967 - val_acc: 0.7625\n",
      "Epoch 3/30\n",
      "9000/9000 [==============================] - 19s 2ms/sample - loss: 0.5295 - acc: 0.7329 - val_loss: 0.4411 - val_acc: 0.7987\n",
      "Epoch 4/30\n",
      "9000/9000 [==============================] - 19s 2ms/sample - loss: 0.4701 - acc: 0.7747 - val_loss: 0.4204 - val_acc: 0.7962\n",
      "Epoch 5/30\n",
      "9000/9000 [==============================] - 19s 2ms/sample - loss: 0.4432 - acc: 0.7971 - val_loss: 0.3887 - val_acc: 0.8350\n",
      "Epoch 6/30\n",
      "9000/9000 [==============================] - 19s 2ms/sample - loss: 0.3938 - acc: 0.8183 - val_loss: 0.3904 - val_acc: 0.8300\n",
      "Epoch 7/30\n",
      "9000/9000 [==============================] - 19s 2ms/sample - loss: 0.3801 - acc: 0.8312 - val_loss: 0.4616 - val_acc: 0.7688\n",
      "Epoch 8/30\n",
      "9000/9000 [==============================] - 19s 2ms/sample - loss: 0.3218 - acc: 0.8594 - val_loss: 0.2938 - val_acc: 0.8725\n",
      "Epoch 9/30\n",
      "9000/9000 [==============================] - 19s 2ms/sample - loss: 0.2981 - acc: 0.8764 - val_loss: 0.3094 - val_acc: 0.8675\n",
      "Epoch 10/30\n",
      "9000/9000 [==============================] - 19s 2ms/sample - loss: 0.2724 - acc: 0.8862 - val_loss: 0.2886 - val_acc: 0.8813\n",
      "Epoch 11/30\n",
      "9000/9000 [==============================] - 19s 2ms/sample - loss: 0.2439 - acc: 0.8961 - val_loss: 0.3270 - val_acc: 0.8875\n",
      "Epoch 12/30\n",
      "9000/9000 [==============================] - 19s 2ms/sample - loss: 0.2233 - acc: 0.9074 - val_loss: 0.2626 - val_acc: 0.9000\n",
      "Epoch 13/30\n",
      "9000/9000 [==============================] - 19s 2ms/sample - loss: 0.2128 - acc: 0.9110 - val_loss: 0.2650 - val_acc: 0.8938\n",
      "Epoch 14/30\n",
      "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.1965 - acc: 0.9184 - val_loss: 0.3088 - val_acc: 0.8900\n",
      "Epoch 15/30\n",
      "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.1806 - acc: 0.9266 - val_loss: 0.2461 - val_acc: 0.8988\n",
      "Epoch 16/30\n",
      "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.1562 - acc: 0.9376 - val_loss: 0.2664 - val_acc: 0.8988\n",
      "Epoch 17/30\n",
      "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.1687 - acc: 0.9314 - val_loss: 0.3322 - val_acc: 0.8813\n",
      "Epoch 18/30\n",
      "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.2124 - acc: 0.9101 - val_loss: 0.2775 - val_acc: 0.8975\n",
      "Epoch 19/30\n",
      "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.1480 - acc: 0.9414 - val_loss: 0.2695 - val_acc: 0.9125\n",
      "Epoch 20/30\n",
      "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.1285 - acc: 0.9484 - val_loss: 0.2612 - val_acc: 0.9062\n",
      "Epoch 21/30\n",
      "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.1208 - acc: 0.9530 - val_loss: 0.2653 - val_acc: 0.9175\n",
      "Epoch 22/30\n",
      "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.1116 - acc: 0.9560 - val_loss: 0.3120 - val_acc: 0.9162\n",
      "Epoch 23/30\n",
      "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.1125 - acc: 0.9542 - val_loss: 0.2700 - val_acc: 0.9100\n",
      "Epoch 24/30\n",
      "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.1063 - acc: 0.9556 - val_loss: 0.3854 - val_acc: 0.9112\n",
      "Epoch 25/30\n",
      "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.1118 - acc: 0.9541 - val_loss: 0.2791 - val_acc: 0.9137\n",
      "Epoch 26/30\n",
      "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.0896 - acc: 0.9623 - val_loss: 0.2875 - val_acc: 0.9200\n",
      "Epoch 27/30\n",
      "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.0865 - acc: 0.9643 - val_loss: 0.2968 - val_acc: 0.9050\n",
      "Epoch 28/30\n",
      "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.0954 - acc: 0.9604 - val_loss: 0.3404 - val_acc: 0.9150\n",
      "Epoch 29/30\n",
      "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.0939 - acc: 0.9616 - val_loss: 0.3101 - val_acc: 0.9100\n",
      "Epoch 30/30\n",
      "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.0970 - acc: 0.9598 - val_loss: 0.3364 - val_acc: 0.9075\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='elu', input_shape=(250, 250, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='elu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='elu'))\n",
    "model.add(layers.Conv2D(100, (3, 3), activation='elu'))\n",
    "model.add(layers.MaxPooling2D((4, 4)))\n",
    "\n",
    "model.add(layers.Conv2D(75, (3, 3), activation='elu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(202, activation='elu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(40, activation='elu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['acc'])\n",
    "#model.summary()\n",
    "history = model.fit(x_train, y_train, validation_data = (x_val, y_val), epochs = 30, \n",
    "          batch_size = 40, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the history to a csv for use in plotting\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "df.to_csv('history.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
